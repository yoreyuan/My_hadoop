Apache Griffin 5.0 ç¼–è¯‘å®‰è£…å’Œä½¿ç”¨(åŒ…å«ä¾èµ–æ— æ³•ä¸‹è½½çš„é—®é¢˜è§£å†³)
----------
[å®˜ç½‘](http://griffin.apache.org/) &nbsp;&nbsp; | &nbsp;&nbsp; 
[Doc](http://griffin.apache.org/docs/quickstart.html) &nbsp;&nbsp; | &nbsp;&nbsp; 
[Apache Griffin Deployment Guide](https://github.com/apache/griffin/blob/master/griffin-doc/deploy/deploy-guide.md) &nbsp;&nbsp; | &nbsp;&nbsp; 
[Apache Griffin Deployment Guide](https://github.com/apache/griffin/blob/master/griffin-doc/deploy/deploy-guide.md)

Big Data Quality Solution For Batch and Streaming

<br/>

# ç›®å½•
* 1 ç®€ä»‹
* 2 ç¼–è¯‘
    * 2.1 å‡†å¤‡
    * 2.2 è·å–æºç åŒ…
        - 2.2.1  ä¸‹è½½å¯¹åº” release ç‰ˆ
        - *2.2.2 cloneæºç 
    * 2.3 é…ç½®
        - 2.3.1 MySQL
        - 2.3.2 ç»„ä»¶çš„ç¯å¢ƒé…ç½®
        - 2.3.3 Hiveé…ç½®
        - 2.3.4 é…ç½® Griffin çš„`application.properties`
        - 2.3.5 é…ç½® Griffin çš„`quartz.properties`
        - 2.3.6 é…ç½® Griffin çš„`sparkProperties.json`
        - 2.3.7 é…ç½® Griffin çš„`env_batch.json`
        - 2.3.8 é…ç½® Griffin çš„`env_streaming.json`
        - 2.3.9 Elasticsearchè®¾ç½®
        - 2.3.10 é©±åŠ¨åŒ…çš„ä¾èµ–ä¿®æ”¹
    * 2.4 ç¼–è¯‘
        - 2.4.1 åˆ‡æ¢åˆ°éœ€è¦çš„ç‰ˆæœ¬
        - 2.4.2 å¼€å§‹ç¼–è¯‘
        - 2.4.3 å¯èƒ½å‡ºç°çš„é—®é¢˜
        - 2.4.4 å¯¹ä¸Šé¢å‡ºç°çš„é—®é¢˜çš„è§£å†³
        - 2.4.5 å†æ¬¡ç¼–è¯‘
* 3 å®‰è£…
    - 3.1 åˆ›å»ºç›®å½•
    - 3.2 é…ç½®Griffinç¯å¢ƒ
    - 3.3 å°†ç¼–è¯‘å¥½çš„æ–‡ä»¶æ”¾ç½®åˆ°ç›®å½•ä¸‹
    - 3.4 å¯åŠ¨service.jarï¼Œè¿è¡ŒGriffinç®¡ç†æœåŠ¡
    - 3.5 è®¿é—® Service Platform WEB é¡µé¢
* 4 æ•°æ®å‡†å¤‡
    - 4.1 å‡†å¤‡demoè¡¨
    - 4.2 è·å–æ¼”ç¤ºæ•°æ®
    - 4.3 åˆ›å»º`gen-hive-data.sh`
    - 4.4 æ‰§è¡Œè„šæœ¬åŠ è½½æ•°æ®
    - 4.5 æŸ¥çœ‹æ•°æ®
* 5 [ä½¿ç”¨]()
    + 5.1 æ•°æ®èµ„äº§
    + 5.2 åˆ›å»º measure
        * 5.2.1 Accuracy 
            - 1 Choose source ï¼ˆé€‰æ‹©æ¥æºï¼‰
            - 2 Choose target ï¼ˆé€‰æ‹©ç›®æ ‡ï¼‰
            - 3 Mapping source and target ï¼ˆæ˜ å°„sourceå’Œtargetï¼‰
            - 4 Partition Configuration ï¼ˆåˆ†åŒºè®¾ç½®ï¼‰
            - 5 Configuration ï¼ˆé…ç½®ï¼‰
            - 6 Measure information ï¼ˆåº¦é‡ä¿¡æ¯ï¼‰
    + 5.3 åˆ›å»º Job
    + 5.4 Metrics ä»ªè¡¨æ¿

*********

# 1 ç®€ä»‹
> Apache Griffin is an open source Data Quality solution for Big Data, which supports both batch and streaming mode. It offers an unified process to measure your data quality from different perspectives, helping you build trusted data assets, therefore boost your confidence for your business.

Apache Griffinæ˜¯å¤§æ•°æ®çš„å¼€æºæ•°æ®è´¨é‡è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒæ‰¹å¤„ç†å’Œæµæ¨¡å¼ã€‚å®ƒæä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æµç¨‹ï¼Œå¯ä»¥ä»ä¸åŒè§’åº¦è¡¡é‡æ‚¨çš„æ•°æ®è´¨é‡ï¼Œå¸®åŠ©æ‚¨æ„å»ºå¯ä¿¡èµ–çš„æ•°æ®èµ„äº§ï¼Œä»è€Œæé«˜æ‚¨å¯¹ä¸šåŠ¡çš„ä¿¡å¿ƒã€‚

> Apache Griffin offers a set of well-defined data quality domain model, which covers most of data quality problems in general. It also define a set of data quality DSL to help users define their quality criteria. By extending the DSL, users are even able to implement their own specific features/functions in Apache Griffin.

Apache Griffinæä¾›äº†ä¸€å¥—å®šä¹‰æ˜ç¡®çš„æ•°æ®è´¨é‡åŸŸæ¨¡å‹ï¼Œå®ƒæ¶µç›–äº†å¤§å¤šæ•°æ•°æ®è´¨é‡é—®é¢˜ã€‚å®ƒè¿˜å®šä¹‰äº†ä¸€ç»„æ•°æ®è´¨é‡DSLï¼Œä»¥å¸®åŠ©ç”¨æˆ·å®šä¹‰ä»–ä»¬çš„è´¨é‡æ ‡å‡†ã€‚é€šè¿‡æ‰©å±•DSLï¼Œç”¨æˆ·ç”šè‡³å¯ä»¥åœ¨Apache Griffinä¸­å®ç°è‡ªå·±çš„ç‰¹å®šåŠŸèƒ½/åŠŸèƒ½ã€‚

Apache Griffinäº2016å¹´12æœˆ7æ—¥è¢«æ¥çº³ä¸ºApacheå­µåŒ–å™¨é¡¹ç›®ã€‚Apache Griffinäº2018å¹´11æœˆ21æ—¥æ¯•ä¸šï¼Œæˆä¸ºApacheé¡¶çº§é¡¹ç›®ã€‚

æ¶æ„å›¾å¦‚ä¸‹
![Griffin ARCHITECTURE ](http://griffin.apache.org/images/arch.png)

# 2 ç¼–è¯‘
å®‰è£… [Apache  griffin](http://griffin.apache.org/) æœ€æ–°ç‰ˆæ—¶ï¼ŒGitHubçš„ release æ˜¯ä¸€ä¸ªæºç åŒ…ï¼Œéœ€è¦ä¸‹è½½ä¸‹æ¥åç¼–è¯‘è¿›è¡Œå®‰è£…å’Œé…ç½®ï¼Œé—®é¢˜æ˜¯ç¼–è¯‘çš„æ—¶å€™æœ‰äº›ä¾èµ–åœ¨ä»“åº“ä¸­æ ¹æœ¬ä¸‹è½½ä¸åˆ°ï¼Œå¯¼è‡´ç¼–è¯‘å¤±è´¥ï¼Œå¯ä»¥æŒ‰ç…§å¦‚ä¸‹æ–¹æ³•è¿›è¡Œç¼–è¯‘ã€‚

## 2.1 å‡†å¤‡
å®‰è£…ä¹‹å‰è¯·ç¡®è®¤ä¸‹é¢çš„ç»„ä»¶å·²ç»å®‰è£…ã€‚å¦‚æœæœ‰æ²¡æœ‰å®‰è£…çš„å¯ä»¥çœ‹å®˜ç½‘æˆ–åšå®¢ï¼Œä¹Ÿå¯ä»¥ç‚¹å‡»é“¾æ¥æŸ¥çœ‹æˆ‘çš„æä¾›çš„ä¸€äº›å®‰è£…æ–‡æ¡£ã€‚

* Git ï¼ˆå¦‚æœç›´æ¥ä¸‹è½½çš„å¯¹åº”çš„releasesç‰ˆï¼Œå¯ä»¥ä¸éœ€è¦ï¼‰
* JDK 1.8 (æˆ–æ›´é«˜)
* Maven
* [Mysql æ•°æ®åº“](https://blog.csdn.net/github_39577257/article/details/77433996) ï¼ˆå¯ä»¥æ˜¯ PostgreSQL ï¼‰
* [npm](https://nodejs.org/en/download/)
* [Scala](https://www.scala-lang.org/download/all.html)

* [Hadoop (2.6.0æˆ–æ›´é«˜ç‰ˆæœ¬)](https://blog.csdn.net/github_39577257/article/details/89020980)
* [Hive (ç‰ˆæœ¬2.x)](https://blog.csdn.net/github_39577257/article/details/89020980)
* [Spark (ç‰ˆæœ¬2.2.1)](https://github.com/yoreyuan/My_spark/blob/spark-demo-2.x/doc/Depoying.md#3-spark-standalone-mode)
* [Livy](https://github.com/yoreyuan/My_hadoop/blob/master/doc/apache-livy.md)
* [ElasticSearch(5.0æˆ–æ›´é«˜ç‰ˆæœ¬)](https://github.com/yoreyuan/My_hadoop/blob/master/doc/elasticsearch-install.md)
* Zookeeper

## 2.2 è·å–æºç åŒ…
ä»¥ä¸‹æ–¹å¼é€‰æ‹©å…¶ä¸€å³å¯
###  2.2.1  ä¸‹è½½å¯¹åº” release ç‰ˆ
* ä¸‹è½½ï¼š ` wget https://github.com/apache/griffin/archive/griffin-0.5.0.tar.gz`
* è§£å‹ï¼š ` tar -zxf griffin-0.5.0.tar.gz `
* è¿›å…¥é¡¹ç›®æºç ç›®å½•ï¼š ` cd  griffin-griffin-0.5.0/ `

### * 2.2.2 cloneæºç 
* è·å–æºç ï¼š ` git clone https://github.com/apache/griffin.git `
* è¿›å…¥é¡¹ç›®æºç ç›®å½•ï¼š ` cd griffin/ `
* æŸ¥çœ‹tagï¼š ` git tag `
* åˆ‡æ¢åˆ°å¯¹åº”çš„ç‰ˆæœ¬(è¿™é‡Œåˆ‡æ¢åˆ°æœ€æ–°ç‰ˆ)ï¼š` git checkout tags/griffin-0.5.0 `
* æŸ¥çœ‹å½“å‰æ‰€å¤„çš„åˆ†æ”¯ï¼š ` git branch `


# 2.3 é…ç½®
## 2.3.1 MySQL
å› ä¸ºGriffinä½¿ç”¨äº† Quartz è¿›è¡Œä»»åŠ¡çš„è°ƒåº¦ï¼Œå› æ­¤éœ€è¦åœ¨MySQLä¸­åˆ›å»ºQuartz è°ƒåº¦å™¨ç”¨åˆ°çš„åº“ã€‚å¹¶è¿›è¡Œåˆå§‹åŒ–
```bash
# åœ¨MySQLæœåŠ¡å™¨ä¸­æ‰§è¡Œå‘½ä»¤ï¼Œåˆ›å»ºä¸€ä¸ª quartz åº“
mysql -u <username> -e "create database quartz" -p
```

åœ¨ä¸‹è½½çš„æºç ä¸­[`service/src/main/resources/Init_quartz_mysql_innodb.sql`](https://github.com/apache/griffin/blob/master/service/src/main/resources/Init_quartz_mysql_innodb.sql)æ‰¾åˆ°sqlè„šæœ¬ï¼Œ
ä¸Šä¼ åˆ°Mysql Serviceï¼Œ ä½¿ç”¨`Init_quartz_mysql_innodb.sql`åœ¨MySQLä¸­åˆå§‹åŒ– Quartzã€‚
```bash
mysql -u <username> -p quartz < Init_quartz_mysql_innodb.sql
```

## 2.3.2 ç»„ä»¶çš„ç¯å¢ƒé…ç½®
`export`ä¸‹é¢çš„å˜é‡ã€‚æˆ–è€…åˆ›å»ºä¸€ä¸ª`griffin_env.sh`æ–‡ä»¶ï¼Œå†™å…¥ä¸‹é¢çš„å†…å®¹ï¼Œå¹¶å°†è„šæœ¬é…ç½®åˆ°`.bashrc`
```bash
#!/bin/bash
export JAVA_HOME=/usr/local/zulu8

export HADOOP_HOME=/opt/hadoop-3.1.2
export HADOOP_COMMON_HOME=/opt/hadoop-3.1.2
export HADOOP_COMMON_LIB_NATIVE_DIR=/opt/hadoop-3.1.2/lib/native
export HADOOP_HDFS_HOME=/opt/hadoop-3.1.2
export HADOOP_INSTALL=/opt/hadoop-3.1.2
export HADOOP_MAPRED_HOME=/opt/hadoop-3.1.2
export HADOOP_USER_CLASSPATH_FIRST=true
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export SPARK_HOME=/opt/spark-2.4.3-bin-hadoop2.7
export LIVY_HOME=/opt/apache-livy-0.6.0-incubating-bin
export HIVE_HOME=/opt/apache-hive-3.1.1-bin
export YARN_HOME=/opt/hadoop-3.1.2
export SCALA_HOME=/usr/share/scala

export PATH=$PATH:$HIVE_HOME/bin:$HADOOP_HOME/bin:$SPARK_HOME/bin:$LIVY_HOME/bin:$SCALA_HOME/bin

```

## 2.3.3 Hiveé…ç½®
åœ¨Sparkä¸­æˆ‘ä»¬é…ç½®è¿‡:
```
spark.yarn.dist.files		hdfs:///home/spark_conf/hive-site.xml
```

è¿™é‡Œä¹Ÿéœ€è¦å°† hive çš„é…ç½®æ–‡ä»¶ `hive-site.xml` ä¸Šä¼ åˆ°hdfsçš„è¿™ä¸ªåœ°æ–¹
```bash
hdfs dfs -put $HIVE_HOME/conf/hive-site.xml hdfs:///home/spark_conf/
```

## 2.3.4 é…ç½® Griffin çš„ [application.properties](https://github.com/apache/griffin/blob/griffin-0.5.0/service/src/main/resources/application.properties)
è¿›å…¥åˆ°ä¸‹è½½çš„æºç ç›®å½•ï¼Œç¼–è¾‘ ` service/src/main/resources/application.properties ` é…ç½®æ–‡ä»¶
```yaml
# Apache Griffin server port (default 8080)
server.port = 8090
spring.application.name=griffin_service

# db configuration
spring.datasource.url=jdbc:mysql://cdh1:3306/quartz?autoReconnect=true&useSSL=false
spring.datasource.username=king
spring.datasource.password=123456
spring.jpa.generate-ddl=true
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.jpa.show-sql=true

# Hive metastore
# è¿™é‡Œé…ç½®çš„å€¼ä¸º`hive-site.xml`ä¸­çš„ `hive.metastore.uris`é…ç½®é¡¹çš„å€¼
hive.metastore.uris=thrift://cdh6:9083
hive.metastore.dbname=hive_metastore
hive.hmshandler.retry.attempts=15
hive.hmshandler.retry.interval=2000ms
# Hive cache time
cache.evict.hive.fixedRate.in.milliseconds=900000

# Kafka schema registry
kafka.schema.registry.url=http://cdh3:9092
# Update job instance state at regular intervals
jobInstance.fixedDelay.in.milliseconds=60000
# Expired time of job instance which is 7 days that is 604800000 milliseconds.Time unit only supports milliseconds
jobInstance.expired.milliseconds=604800000
# schedule predicate job every 5 minutes and repeat 12 times at most
#interval time unit s:second m:minute h:hour d:day,only support these four units
predicate.job.interval=5m
predicate.job.repeat.count=12
# external properties directory location
external.config.location=
# external BATCH or STREAMING env
external.env.location=
# login strategy ("default" or "ldap")
login.strategy=default
# ldap
ldap.url=ldap://hostname:port
ldap.email=@example.com
ldap.searchBase=DC=org,DC=example
ldap.searchPattern=(sAMAccountName={0})
# hdfs default name
fs.defaultFS=hdfs://cdh6:8020

# elasticsearch
# elasticsearch.host = <IP>
# elasticsearch.port = <elasticsearch rest port>
# elasticsearch.user = user
# elasticsearch.password = password
elasticsearch.host=cdh2
elasticsearch.port=9200
elasticsearch.scheme=http

# livy
livy.uri=http://cdh6:8998/batches
# yarn url
yarn.uri=http://cdh6:8088
# griffin event listener
internal.event.listeners=GriffinJobEventHook

# å‹ç¼©
server.compression.enabled=true
server.compression.mime-types=application/json,application/xml,text/html,text/xml,text/plain,application/javascript,text/css

```

## 2.3.5 é…ç½® Griffin çš„ [quartz.properties](https://github.com/apache/griffin/blob/griffin-0.5.0/service/src/main/resources/quartz.properties)
è¿›å…¥åˆ°ä¸‹è½½çš„æºç ç›®å½•ï¼Œç¼–è¾‘ ` service/src/main/resources/quartz.properties ` é…ç½®æ–‡ä»¶ã€‚é»˜è®¤äº¦å¯ã€‚
```yaml
org.quartz.scheduler.instanceName=spring-boot-quartz
org.quartz.scheduler.instanceId=AUTO
org.quartz.threadPool.threadCount=5
org.quartz.jobStore.class=org.quartz.impl.jdbcjobstore.JobStoreTX
# If you use postgresql, set this property value to org.quartz.impl.jdbcjobstore.PostgreSQLDelegate
# If you use mysql, set this property value to org.quartz.impl.jdbcjobstore.StdJDBCDelegate
# If you use h2, it's ok to set this property value to StdJDBCDelegate, PostgreSQLDelegate or others
org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.PostgreSQLDelegate
org.quartz.jobStore.useProperties=true
org.quartz.jobStore.misfireThreshold=60000
org.quartz.jobStore.tablePrefix=QRTZ_
org.quartz.jobStore.isClustered=true
org.quartz.jobStore.clusterCheckinInterval=20000
```

## 2.3.6 é…ç½® Griffin çš„ [sparkProperties.json](https://github.com/apache/griffin/blob/griffin-0.5.0/service/src/main/resources/sparkProperties.json)
è¿›å…¥åˆ°ä¸‹è½½çš„æºç ç›®å½•ï¼Œç¼–è¾‘ ` service/src/main/resources/sparkProperties.json ` é…ç½®æ–‡ä»¶ã€‚å…ˆé…ç½®ä¸Š`griffin-measure.jar`åœ¨hdfsä¸Šçš„ä½ç½®ï¼Œ
`spark.yarn.dist.files`å³ä¸º[1.3.3](#1.3.3)é‚£é‡Œhive-site.xmlä¸Šä¼ çš„ä½ç½®ã€‚
```json
{
  "file": "hdfs://cdh6:8020/griffin/griffin-measure.jar",
  "className": "org.apache.griffin.measure.Application",
  "name": "griffin",
  "queue": "default",
  "numExecutors": 2,
  "executorCores": 1,
  "driverMemory": "1g",
  "executorMemory": "1g",
  "conf": {
    "spark.yarn.dist.files": "hdfs://cdh6:8020/home/spark_conf/hive-site.xml"
  },
  "files": [
  ]
}
```


## 2.3.7 é…ç½® Griffin çš„ [env_batch.json](https://github.com/apache/griffin/blob/griffin-0.5.0/service/src/main/resources/env/env_batch.json)
è¿›å…¥åˆ°ä¸‹è½½çš„æºç ç›®å½•ï¼Œç¼–è¾‘ ` service/src/main/resources/env/env_batch.json ` é…ç½®æ–‡ä»¶ã€‚æ ¹æ®è‡ªå·±çš„éœ€æ±‚è°ƒæ•´sinkä¿¡æ¯ã€‚é…ç½®HDFSçš„è¾“å‡ºè·¯å¾„å’ŒElasticsearch URLã€‚
```json
{
  "spark": {
    "log.level": "WARN"
  },
  "sinks": [
    {
      "type": "CONSOLE",
      "config": {
        "max.log.lines": 10
      }
    },
    {
      "type": "HDFS",
      "config": {
        "path": "hdfs://cdh6:8020/griffin/persist",
        "max.persist.lines": 10000,
        "max.lines.per.file": 10000
      }
    },
    {
      "type": "ELASTICSEARCH",
      "config": {
        "method": "post",
        "api": "http://cdh2:9200/griffin/accuracy",
        "connection.timeout": "1m",
        "retry": 10
      }
    }
  ],
  "griffin.checkpoint": []
}

```

## 2.3.8 é…ç½® Griffin çš„ [env_streaming.json](https://github.com/apache/griffin/blob/griffin-0.5.0/service/src/main/resources/env/env_streaming.json)
è¿›å…¥åˆ°ä¸‹è½½çš„æºç ç›®å½•ï¼Œç¼–è¾‘ ` service/src/main/resources/env/env_streaming.json ` é…ç½®æ–‡ä»¶ã€‚åŒenv_batch.jsonçš„æ›´æ”¹ç±»ä¼¼ã€‚
```json
{
  "spark": {
    "log.level": "WARN",
    "checkpoint.dir": "hdfs://cdh6:8020/griffin/checkpoint/${JOB_NAME}",
    "init.clear": true,
    "batch.interval": "1m",
    "process.interval": "5m",
    "config": {
      "spark.default.parallelism": 4,
      "spark.task.maxFailures": 5,
      "spark.streaming.kafkaMaxRatePerPartition": 1000,
      "spark.streaming.concurrentJobs": 4,
      "spark.yarn.maxAppAttempts": 5,
      "spark.yarn.am.attemptFailuresValidityInterval": "1h",
      "spark.yarn.max.executor.failures": 120,
      "spark.yarn.executor.failuresValidityInterval": "1h",
      "spark.hadoop.fs.hdfs.impl.disable.cache": true
    }
  },
  "sinks": [
    {
      "type": "CONSOLE",
      "config": {
        "max.log.lines": 100
      }
    },
    {
      "type": "HDFS",
      "config": {
        "path": "hdfs://cdh6:8020/griffin/persist",
        "max.persist.lines": 10000,
        "max.lines.per.file": 10000
      }
    },
    {
      "type": "ELASTICSEARCH",
      "config": {
        "method": "post",
        "api": "http://cdh2:9200/griffin/accuracy"
      }
    }
  ],
  "griffin.checkpoint": [
    {
      "type": "zk",
      "config": {
        "hosts": "cdh1:2181,cdh2:2181,cdh3:2181",
        "namespace": "griffin/infocache",
        "lock.path": "lock",
        "mode": "persist",
        "init.clear": true,
        "close.clear": false
      }
    }
  ]
}

```

## 2.3.9 Elasticsearchè®¾ç½®
è¿™é‡Œæå‰åœ¨Elasticsearchè®¾ç½®ç´¢å¼•ï¼Œä»¥ä¾¿å°†åˆ†ç‰‡æ•°ï¼Œå‰¯æœ¬æ•°å’Œå…¶ä»–è®¾ç½®è®¾ç½®ä¸ºæ‰€éœ€çš„å€¼ï¼š
```bash
curl -k -H "Content-Type: application/json" -X PUT http://cdh2:9200/griffin \
 -d '{
    "aliases": {},
    "mappings": {
        "accuracy": {
            "properties": {
                "name": {
                    "fields": {
                        "keyword": {
                            "ignore_above": 256,
                            "type": "keyword"
                        }
                    },
                    "type": "text"
                },
                "tmst": {
                    "type": "date"
                }
            }
        }
    },
    "settings": {
        "index": {
            "number_of_replicas": "2",
            "number_of_shards": "5"
        }
    }
}'
```

åˆ›å»ºæˆåŠŸåä¼šè¿”å›ï¼Œå¦‚æœå®‰è£…äº†Elasticsearch headå·¥å…·ï¼Œå¯ä»¥åœ¨Webé¡µé¢ä¸Šçœ‹åˆ°æˆ‘ä»¬åˆ›å»ºçš„ç´¢å¼•ä¿¡æ¯ã€‚
```json
{"acknowledged":true,"shards_acknowledged":true,"index":"griffin"}
```


## 2.3.10 é©±åŠ¨åŒ…çš„ä¾èµ–ä¿®æ”¹
ç¼–è¯‘ä¹‹å‰éœ€è¦ä¿®æ”¹ä¸‹Mysqlé©±åŠ¨çš„ä¾èµ–èŒƒå›´ï¼Œå¦åˆ™å¯åŠ¨åä¼šæŠ¥å¦‚ä¸‹çš„é”™è¯¯ï¼š
```
Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.apache.tomcat.jdbc.pool.DataSource]: Factory method 'dataSource' threw exception; nested exception is java.lang.IllegalStateException: Cannot load driver class: com.mysql.jdbc.Driver
	â€¦â€¦
	... 36 more
Caused by: java.lang.IllegalStateException: Cannot load driver class: com.mysql.jdbc.Driver
	â€¦â€¦
	... 36 more
```

åŸå› ä¸ºç¨‹åºå¯åŠ¨æ— æ³•åŠ è½½jdbcé©±åŠ¨ç±»ï¼Œå› æ­¤ç¼–è¾‘`service/pom.xml`ï¼Œå¤§æ¦‚åœ¨113è¡Œï¼Œå°†æ³¨é‡Šçš„`mysql-connector-java`é‡Šæ”¾å¼€ã€‚
```xml
    <dependency>
        <groupId>mysql</groupId>
        <artifactId>mysql-connector-java</artifactId>
        <version>${mysql.java.version}</version>
    </dependency>
```


## 2.4 ç¼–è¯‘

### 2.4.1 (ç›´æ¥ä¸‹è½½çš„å¯¹åº”ç‰ˆæœ¬çš„å¯ä»¥è·³è¿‡æ­¤æ­¥)åˆ‡æ¢åˆ°éœ€è¦çš„ç‰ˆæœ¬
å¦‚æœæ˜¯cloneçš„æºç ï¼Œéœ€è¦åˆ‡å…¥åˆ°ä¸€ä¸ªç‰ˆæœ¬ï¼Œå†è¿›è¡Œç¼–è¯‘ã€‚æŸ¥çœ‹åˆ°å„ä¸ªç‰ˆæœ¬ï¼Œ
```bash
[root@cdh6 griffin]# git tag
griffin-0.1.4-incubating
griffin-0.1.5-incubating
griffin-0.1.6-incubating
griffin-0.2.0-incubating
griffin-0.3.0-incubating
griffin-0.4.0
griffin-0.4.0-incubating
griffin-0.5.0
```

åˆ‡æ¢åˆ°æœ€æ–°ç‰ˆæœ¬ `griffin-0.5.0`
```
[root@cdh griffin]# git checkout tags/griffin-0.5.0
Note: checking out 'tags/griffin-0.5.0'.
You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by performing another checkout.
If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -b with the checkout command again. Example:
  git checkout -b new_branch_name
HEAD is now at a3a71ac... [maven-release-plugin] prepare release griffin-0.5.0
```

æŸ¥çœ‹å½“å‰æ‰€å¤„åˆ†æ”¯
è¾“å…¥å¦‚ä¸‹å‘½ä»¤ï¼Œå¯ä»¥çœ‹åˆ°å½“å‰å·²ç»åˆ‡æ¢åˆ°æˆ‘ä»¬éœ€è¦çš„åˆ†æ”¯ä¸Šäº†ã€‚
```
[root@cdh griffin]# git branch
* (detached from griffin-0.5.0)
  master
```

### 2.4.2 å¼€å§‹ç¼–è¯‘
ä½¿ç”¨mavenå‘½ä»¤ç¼–è¯‘é¡¹ç›®ï¼Œè·³è¿‡æµ‹è¯•å¯ä»¥åŠ å¿«ç¼–è¯‘è¿‡ç¨‹çš„é€Ÿåº¦
```bash
mvn clean
mvn -T2C install -DskipTests
```
**-T2C**ï¼šä¸€ä¸ªCPUæ ¸å¿ƒå¯åŠ¨ä¸¤ä¸ªçº¿ç¨‹è¿›è¡Œç¼–è¯‘ï¼Œå¯ä»¥åŠ å¿«æºç ç¼–è¯‘çš„é€Ÿåº¦ã€‚
**install**ï¼šå°†ç¼–è¯‘å®Œæºç ç›´æ¥å®‰è£…åˆ°Mavenåº“ä¸­ã€‚
**-DskipTests**ï¼šè·³è¿‡æµ‹è¯•å·¥ç¨‹å’Œæµ‹è¯•ç±»ã€‚




### 2.4.3 å¯èƒ½å‡ºç°çš„é—®é¢˜
å¦‚æœæ­¤æ—¶åŒ…å¦‚ä¸‹é”™è¯¯ï¼Œç¼ºå°‘  `kafka-schema-registry-client`ï¼Œå¯æŒ‰ç…§å¦‚ä¸‹æ–¹å¼è§£å†³ï¼š
```
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary for Apache Griffin 0.5.0 0.5.0:
[INFO]
[INFO] Apache Griffin 0.5.0 ............................... SUCCESS [  9.715 s]
[INFO] Apache Griffin :: UI :: Default UI ................. SKIPPED
[INFO] Apache Griffin :: Web Service ...................... FAILURE [02:55 min]
[INFO] Apache Griffin :: Measures ......................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  03:08 min (Wall Clock)
[INFO] Finished at: 2019-05-27T14:27:07+08:00
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal on project service: Could not resolve dependencies for project org.apache.griffin:service:jar:0.5.0: Could not find artifact io.confluent:kafka-schema-registry-client:jar:3.2.0 in nexus-aliyun (http://maven.aliyun.com/nexus/content/groups/public) -> [Help 1]
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException
[ERROR]
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :service
```

### 2.4.4 å¯¹ä¸Šé¢å‡ºç°çš„é—®é¢˜çš„è§£å†³

æœ¬æƒ³æˆ‘ä»¬æ‰‹åŠ¨æŠŠ `kafka-schema-registry-client-3.2.0.jar` ä¸‹è½½ä¸‹æ¥å¯¼å…¥å°±è¡Œäº†å˜›ï¼Œç„¶è€Œç°å®æ˜¯å°±æ˜¯å¦‚æ­¤éª¨æ„Ÿï¼Œæˆ‘ä»¬è®¿é—® Mavenä»“åº“ï¼Œ`https://mvnrepository.com/artifact/io.confluent/kafka-schema-registry-client` ï¼Œå‘ç°å¹¶æ²¡æœ‰æˆ‘ä»¬éœ€è¦çš„ç‰ˆæœ¬ `3.2.0` ï¼Œè€Œæ˜¯
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/20190527161619170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dpdGh1Yl8zOTU3NzI1Nw==,size_16,color_FFFFFF,t_70)
äºæ˜¯æˆ‘ä»¬æ˜¯ä¸æ˜¯åˆæƒ³ï¼Œé‚£æˆ‘ä»¬æŠŠæºç ä¸­çš„ `kafka-schema-registry-client` ç‰ˆæœ¬æ”¹ä¸º3.3.1æˆ–è€…3.3.0ï¼Œé‡æ–°ç¼–è¯‘ä¸‹å°±è¡Œäº†å˜›ï¼Œæˆ‘ä»¬å¾ˆå®¹æ˜“åœ¨cloneä¸‹çš„æºç  `griffin/service` çš„ `pom.xml`  å¤§æ¦‚åœ¨41è¡Œæ‰¾åˆ° `        <confluent.version>3.2.0</confluent.version>` æŠŠè¿™ä¸ªä¿®æ”¹æˆ 3.3.1ï¼Œç„¶åä¿å­˜ï¼Œé‡æ–°ç¼–è¯‘ï¼Œç„¶è€Œåˆä¼šå‘ç°å‡ºç°äº†å¦‚ä¸‹çš„é”™è¯¯
```
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  31.256 s (Wall Clock)
[INFO] Finished at: 2019-05-27T14:53:27+08:00
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.1:compile (default-compile) on project service: Compilation failure: Compilation failure:
[ERROR] error reading /opt/.m2/repository/io/confluent/kafka-schema-registry-client/3.3.1/kafka-schema-registry-client-3.3.1.jar; error in opening zip file
[ERROR] error reading /opt/.m2/repository/io/confluent/kafka-schema-registry-client/3.3.1/kafka-schema-registry-client-3.3.1.jar; error in opening zip file
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaServiceImpl.java:[24,62] package io.confluent.kafka.schemaregistry.client.rest.entities does not exist
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaServiceImpl.java:[25,62] package io.confluent.kafka.schemaregistry.client.rest.entities does not exist
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaServiceImpl.java:[26,62] package io.confluent.kafka.schemaregistry.client.rest.entities does not exist
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaService.java:[22,62] package io.confluent.kafka.schemaregistry.client.rest.entities does not exist
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaService.java:[23,62] package io.confluent.kafka.schemaregistry.client.rest.entities does not exist
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaService.java:[24,62] package io.confluent.kafka.schemaregistry.client.rest.entities does not exist
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaServiceImpl.java:[58,12] cannot find symbol
[ERROR]   symbol:   class SchemaString
[ERROR]   location: class org.apache.griffin.core.metastore.kafka.KafkaSchemaServiceImpl
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaServiceImpl.java:[88,12] cannot find symbol
[ERROR]   symbol:   class Schema
[ERROR]   location: class org.apache.griffin.core.metastore.kafka.KafkaSchemaServiceImpl
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaServiceImpl.java:[98,12] cannot find symbol
[ERROR]   symbol:   class Config
[ERROR]   location: class org.apache.griffin.core.metastore.kafka.KafkaSchemaServiceImpl
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaServiceImpl.java:[108,12] cannot find symbol
[ERROR]   symbol:   class Config
[ERROR]   location: class org.apache.griffin.core.metastore.kafka.KafkaSchemaServiceImpl
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaService.java:[27,5] cannot find symbol
[ERROR]   symbol:   class SchemaString
[ERROR]   location: interface org.apache.griffin.core.metastore.kafka.KafkaSchemaService
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaService.java:[33,5] cannot find symbol
[ERROR]   symbol:   class Schema
[ERROR]   location: interface org.apache.griffin.core.metastore.kafka.KafkaSchemaService
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaService.java:[35,5] cannot find symbol
[ERROR]   symbol:   class Config
[ERROR]   location: interface org.apache.griffin.core.metastore.kafka.KafkaSchemaService
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaService.java:[37,5] cannot find symbol
[ERROR]   symbol:   class Config
[ERROR]   location: interface org.apache.griffin.core.metastore.kafka.KafkaSchemaService
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaController.java:[22,62] package io.confluent.kafka.schemaregistry.client.rest.entities does not exist
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaController.java:[23,62] package io.confluent.kafka.schemaregistry.client.rest.entities does not exist
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaController.java:[24,62] package io.confluent.kafka.schemaregistry.client.rest.entities does not exist
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaController.java:[40,12] cannot find symbol
[ERROR]   symbol:   class SchemaString
[ERROR]   location: class org.apache.griffin.core.metastore.kafka.KafkaSchemaController
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaController.java:[56,12] cannot find symbol
[ERROR]   symbol:   class Schema
[ERROR]   location: class org.apache.griffin.core.metastore.kafka.KafkaSchemaController
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaController.java:[62,12] cannot find symbol
[ERROR]   symbol:   class Config
[ERROR]   location: class org.apache.griffin.core.metastore.kafka.KafkaSchemaController
[ERROR] /home/yore/griffin/service/src/main/java/org/apache/griffin/core/metastore/kafka/KafkaSchemaController.java:[67,12] cannot find symbol
[ERROR]   symbol:   class Config
[ERROR]   location: class org.apache.griffin.core.metastore.kafka.KafkaSchemaController
[ERROR] -> [Help 1]
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR]
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :service
```
å‘ç°å¼•å…¥çš„è¿™ä¸ªç‰ˆæœ¬æ²¡æœ‰ `io.confluent.kafka.schemaregistry.client.rest.entities` ä¸ªæ–¹æ³•ï¼Œå¾—äº†ï¼Œè¿˜æ˜¯è€è€å®å®æŸ¥çœ‹å®˜ç½‘ï¼Œä¸‹è½½  `kafka-schema-registry-client-3.2.0.jar` å§ã€‚
è®¿é—®å®˜ç½‘ï¼Œç„¶åæ‰¾åˆ°å†å²ç‰ˆæœ¬çš„ä¸‹è½½é¡µé¢ [Previous Versions](https://www.confluent.io/previous-versions/)ï¼Œç‚¹å‡»å¦‚ä¸‹ä¸‹è½½ï¼š

![Previous Versions](https://img-blog.csdnimg.cn/20190527163159827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2dpdGh1Yl8zOTU3NzI1Nw==,size_16,color_FFFFFF,t_70)

å¦‚æœç½‘é€Ÿä¸å¥½çš„è¯ï¼Œéœ€è¦ç¨ç­‰ä¼šå„¿ï¼Œæ–‡ä»¶confluent-oss-3.2.0-2.11.tar.gz.tar å¤§æ¦‚4ç™¾å¤šå…†ã€‚

å°†ä¸‹è½½åçš„ `confluent-oss-3.2.0-2.11.tar.gz.tar` è§£å‹ï¼Œå¾—åˆ° `confluent-3.2` æ–‡ä»¶ï¼Œç„¶åè¿›å…¥åˆ° `share/java/camus/` ä¸‹å¯ä»¥çœ‹åˆ° `kafka-schema-registry-client-3.2.0.jar` æ–‡ä»¶ï¼Œè¿™ä¸ªå°±æ˜¯æˆ‘ä»¬éœ€è¦çš„ï¼Œå°†è¿™ä¸ªæ–‡ä»¶ä¸Šä¼ åˆ°æœåŠ¡å™¨ä¸Šã€‚

å°† `kafka-schema-registry-client-3.2.0.jar` æ‰‹åŠ¨å°†jaråŒ…å¯¼å…¥åˆ°æœ¬åœ°Mavenåº“ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š
```bash
mvn install:install-file -DgroupId=io.confluent -DartifactId=kafka-schema-registry-client -Dversion=3.2.0 -Dpackaging=jar -Dfile=kafka-schema-registry-client-3.2.0.jar
```

### 2.4.5 å†æ¬¡ç¼–è¯‘
å…ˆè¯·æ±‚ä¸Šæ¬¡ç¼–è¯‘å¤±è´¥çš„æ–‡ä»¶ï¼Œç„¶åå†æ¬¡ç¼–è¯‘`Griffin`
```bash
mvn clean
mvn -T2C install -DskipTests
```

è¿™æ¬¡é¡ºåˆ©ç¼–è¯‘æˆåŠŸ
```
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary for Apache Griffin 0.5.0 0.5.0:
[INFO]
[INFO] Apache Griffin 0.5.0 ............................... SUCCESS [  3.925 s]
[INFO] Apache Griffin :: UI :: Default UI ................. SUCCESS [03:46 min]
[INFO] Apache Griffin :: Web Service ...................... SUCCESS [03:03 min]
[INFO] Apache Griffin :: Measures ......................... SUCCESS [01:30 min]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  04:02 min (Wall Clock)
[INFO] Finished at: 2019-05-27T15:49:03+08:00
[INFO] ------------------------------------------------------------------------
```

<br/>



# 3 å®‰è£…

## 3.1 åˆ›å»ºç›®å½•
```bash
# åˆ›å»ºGriffinå®‰è£…çš„ä½ç½®
mkdir /opt/griffin-0.5.0

# Hadoopéœ€è¦çš„è·¯å¾„
hadoop fs -mkdir -p /griffin/persist
hadoop fs -mkdir /griffin/checkpoint

```

## 3.2 é…ç½®Griffinç¯å¢ƒ
```bash
vim ~/.bash_profile
```
æ·»åŠ å¦‚ä¸‹é…ç½®ï¼Œä¿å­˜å¹¶æ¨å‡ºã€‚
```bash
#Griffiné…ç½®
export GRIFFIN_HOME=/opt/griffin-0.5.0
```

## 3.3 å°†ç¼–è¯‘å¥½çš„æ–‡ä»¶æ”¾ç½®åˆ°ç›®å½•ä¸‹
```bash
# é‡å‘½åmeasureã€service
mv measure/target/measure-0.5.0.jar $GRIFFIN_HOME/griffin-measure.jar
mv service/target/service-0.5.0.jar $GRIFFIN_HOME/griffin-service.jar

# å°†measureä¸Šä¼ åˆ°HDFS
hadoop fs -put $GRIFFIN_HOME/griffin-measure.jar /griffin/

```

## 3.4 å¯åŠ¨service.jarï¼Œè¿è¡ŒGriffinç®¡ç†æœåŠ¡ã€‚
```bash
# å¯åŠ¨ä¹‹å‰è¯·ç¡®ä¿Hiveçš„ metastore æœåŠ¡æ­£å¸¸å¼€å¯
nohup java -jar $GRIFFIN_HOME/griffin-service.jar>$GRIFFIN_HOME/service.out 2>&1 &
```

å¯åŠ¨ä¹‹åæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹å¯åŠ¨æ—¥å¿—ï¼Œå¦‚æœæ—¥å¿—ä¸­æ²¡æœ‰é”™è¯¯ï¼Œåˆ™å¯åŠ¨æˆåŠŸï¼Œ
```bash
tail -f $GRIFFIN_HOME/service.out
```

## 3.5 è®¿é—® Service Platform WEB é¡µé¢
å‡ ç§’é’Ÿä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥è®¿é—®Apache Griffinçš„ UI [http://cdh6:8090](http://cdh6:8090)ï¼Œå…¶ç«¯å£å·ä¸º`application.properties`ä¸­çš„server.portå€¼ã€‚

![Service Platform WEB UI](image/griffin-web-ui.png)
è¾“å…¥ç”¨æˆ·åå’Œå¯†ç 
* username: user
* password: test


<br/>



# 4 æ•°æ®å‡†å¤‡
## 4.1 å‡†å¤‡demoè¡¨
```bash
hive -e "create database griffin_demo"
hive --database griffin_demo
```
åˆ›å»ºdemoè¡¨
```sql
hive> CREATE EXTERNAL TABLE `demo_src`(
    >   `id` bigint,
    >   `age` int,
    >   `desc` string)
    > PARTITIONED BY (
    >   `dt` string,
    >   `hour` string)
    > ROW FORMAT DELIMITED
    >   FIELDS TERMINATED BY '|'
    > LOCATION
    >   'hdfs://cdh6:8020/griffin/data/batch/demo_src';

hive> CREATE EXTERNAL TABLE `demo_tgt`(
    >   `id` bigint,
    >   `age` int,
    >   `desc` string)
    > PARTITIONED BY (
    >   `dt` string,
    >   `hour` string)
    > ROW FORMAT DELIMITED
    >   FIELDS TERMINATED BY '|'
    > LOCATION
    >   'hdfs://cdh6:8020/griffin/data/batch/demo_tgt';

hive> show tables;
OK
demo_src
demo_tgt
Time taken: 0.051 seconds, Fetched: 2 row(s)

-- æ£€æŸ¥è¡¨çš„å®šä¹‰
hive> show create table demo_src;
OK
CREATE EXTERNAL TABLE `demo_src`(
  `id` bigint,
  `age` int,
  `desc` string)
PARTITIONED BY (
  `dt` string,
  `hour` string)
ROW FORMAT SERDE
  'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
WITH SERDEPROPERTIES (
  'field.delim'='|',
  'serialization.format'='|')
STORED AS INPUTFORMAT
  'org.apache.hadoop.mapred.TextInputFormat'
OUTPUTFORMAT
  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION
  'hdfs://cdh6:8020/griffin/data/batch/demo_src'
TBLPROPERTIES (
  'bucketing_version'='2',
  'transient_lastDdlTime'='1563416877')
Time taken: 0.215 seconds, Fetched: 21 row(s)

-- å¦‚æœæœ‰é—®é¢˜ï¼Œåˆ é™¤åå†é‡æ–°åˆ›å»º
-- drop table if exists demo_src;
-- drop table if exists demo_tgt;

```

## 4.2 [è·å–æ¼”ç¤ºæ•°æ®](http://griffin.apache.org/data/batch/)
```bash
cd $GRIFFIN_HOME/data
wget http://griffin.apache.org/data/batch/gen_demo_data.sh
wget http://griffin.apache.org/data/batch/gen_delta_src.sh
wget http://griffin.apache.org/data/batch/demo_basic
wget http://griffin.apache.org/data/batch/delta_src
wget http://griffin.apache.org/data/batch/delta_tgt
wget http://griffin.apache.org/data/batch/insert-data.hql.template
#å¦‚æœå‰é¢å·²ç»æˆåŠŸåˆ›å»ºäº† demo_src demo_tgtï¼Œå¯ä»¥ä¸ç”¨ä¸‹è½½è¿™ä¸ªè„šæœ¬
#wget http://griffin.apache.org/data/batch/create-table.hql
chmod 755 *.sh
./gen_demo_data.sh

```

æŸ¥çœ‹ç”Ÿæˆçš„æ•°æ®å¦‚ä¸‹ï¼š
```bash
[root@cdh6 data]# head -3 delta_src
124|262|262
124|1752|1752
124|533|533
[root@cdh6 data]# head -3 demo_src
0|1|1
0|2|2
0|3|3
[root@cdh6 data]# head -3 demo_tgt
0|1|1
0|2|2
0|3|3
```

## 4.3 åˆ›å»º `gen-hive-data.sh`
åœ¨`$GRIFFIN_HOME/data`ä¸‹åˆ›å»ºå¦‚Hiveæ•°æ®ç”Ÿæˆçš„è„šæœ¬
```bash
#!/bin/bash

#create tableã€‚å› ä¸ºå‰é¢å·²ç»æ‰‹åŠ¨åˆ›å»ºï¼Œè¿™é‡Œæ³¨é‡Šï¼Œä¸ç”¨å†æ¬¡åˆ›å»ºäº†
#hive -f create-table.hql
echo "create table done"

#current hour
sudo ./gen_demo_data.sh
cur_date=`date +%Y%m%d%H`
dt=${cur_date:0:8}
hour=${cur_date:8:2}
partition_date="dt='$dt',hour='$hour'"
sed s/PARTITION_DATE/$partition_date/ ./insert-data.hql.template > insert-data.hql
hive -f insert-data.hql
src_done_path=/griffin/data/batch/demo_src/dt=${dt}/hour=${hour}/_DONE
tgt_done_path=/griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}/_DONE
hadoop fs -mkdir -p /griffin/data/batch/demo_src/dt=${dt}/hour=${hour}
hadoop fs -mkdir -p /griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}
hadoop fs -touchz ${src_done_path}
hadoop fs -touchz ${tgt_done_path}
echo "insert data [$partition_date] done"

#last hour
sudo ./gen_demo_data.sh
cur_date=`date -d '1 hour ago' +%Y%m%d%H`
dt=${cur_date:0:8}
hour=${cur_date:8:2}
partition_date="dt='$dt',hour='$hour'"
sed s/PARTITION_DATE/$partition_date/ ./insert-data.hql.template > insert-data.hql
hive -f insert-data.hql
src_done_path=/griffin/data/batch/demo_src/dt=${dt}/hour=${hour}/_DONE
tgt_done_path=/griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}/_DONE
hadoop fs -mkdir -p /griffin/data/batch/demo_src/dt=${dt}/hour=${hour}
hadoop fs -mkdir -p /griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}
hadoop fs -touchz ${src_done_path}
hadoop fs -touchz ${tgt_done_path}
echo "insert data [$partition_date] done"

#next hours
set +e
while true
do
  sudo ./gen_demo_data.sh
  cur_date=`date +%Y%m%d%H`
  next_date=`date -d "+1hour" '+%Y%m%d%H'`
  dt=${next_date:0:8}
  hour=${next_date:8:2}
  partition_date="dt='$dt',hour='$hour'"
  sed s/PARTITION_DATE/$partition_date/ ./insert-data.hql.template > insert-data.hql
  hive -f insert-data.hql
  src_done_path=/griffin/data/batch/demo_src/dt=${dt}/hour=${hour}/_DONE
  tgt_done_path=/griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}/_DONE
  hadoop fs -mkdir -p /griffin/data/batch/demo_src/dt=${dt}/hour=${hour}
  hadoop fs -mkdir -p /griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}
  hadoop fs -touchz ${src_done_path}
  hadoop fs -touchz ${tgt_done_path}
  echo "insert data [$partition_date] done"
  sleep 3600
done
set -e

```

**æ³¨æ„**ï¼š å¦‚æœæ¼”ç¤ºä½¿ç”¨çš„åº“ä¸æ˜¯defalutï¼Œéœ€è¦ä¿®æ”¹`insert-data.hql.template`è„šæœ¬å¦‚ä¸‹ã€‚ä¾‹å¦‚ä½¿ç”¨`griffin_demo`åº“æ—¶ä¿®æ”¹ä¸ºå¦‚ä¸‹
```sql
LOAD DATA LOCAL INPATH 'demo_src' INTO TABLE griffin_demo.demo_src PARTITION (PARTITION_DATE);
LOAD DATA LOCAL INPATH 'demo_tgt' INTO TABLE griffin_demo.demo_tgt PARTITION (PARTITION_DATE);
```

## 4.4 æ‰§è¡Œè„šæœ¬åŠ è½½æ•°æ®
æ‰§è¡Œä¸Šè¿°è„šæœ¬
```bash
chmod +x gen-hive-data.sh
./gen-hive-data.sh
```

åŠ è½½å®Œæˆåï¼Œå¾€hiveè¡¨ä¸­ `griffin_demo.demo_src`è¡¨å’Œ `griffin_demo.demo_tgt` åˆ†åˆ«æ’å…¥375000æ¡æ•°æ®ã€‚

## 4.5 æŸ¥çœ‹æ•°æ®
è¿‡æ®µæ—¶é—´æˆ‘ä»¬å°±å¯ä»¥æŸ¥çœ‹æ•°æ®ï¼Œ
```sql
-- æŸ¥çœ‹hiveçš„æ•°æ®
hive> select * from demo_src limit 3;
OK
0       1       1       20190707        10
0       2       2       20190707        10
0       3       3       20190707        10
Time taken: 0.236 seconds, Fetched: 3 row(s)
hive> select * from demo_tgt limit 3;

```

æŸ¥çœ‹HDFSä¸Šçš„æ•°æ®
```bash
[root@cdh6 data]# hdfs dfs -ls /griffin/data/batch
Found 2 items
drwxr-xr-x   - root supergroup          0 2019-07-07 11:22 /griffin/data/batch/demo_src
drwxr-xr-x   - root supergroup          0 2019-07-07 11:22 /griffin/data/batch/demo_tgt
[root@cdh6 data]# hdfs dfs -ls /griffin/data/batch/demo_src/
Found 1 items
drwxr-xr-x   - root supergroup          0 2019-07-07 11:23 /griffin/data/batch/demo_src/dt=20190707
```

# 5 [ä½¿ç”¨](https://github.com/apache/griffin/blob/master/griffin-doc/ui/user-guide.md)
ç™»é™†ç³»ç»Ÿï¼Œè®¿é—®Apache Griffinçš„ UI [http://cdh6:8090](http://cdh6:8090)

## 5.1 æ•°æ®èµ„äº§
æ‚¨å¯ä»¥é€šè¿‡å•å‡»å³ä¸Šè§’çš„â€œDataAssetsâ€æ¥æ£€æŸ¥æ•°æ®èµ„äº§ã€‚
![DataAssets](image/griffin-web-ui-01.png)

## 5.2 åˆ›å»º measure
å•å‡»å¤´éƒ¨çš„â€œMeasuresâ€ï¼Œç„¶åé€‰æ‹©â€œCreate Measureâ€ã€‚å¯ä»¥ä½¿ç”¨è¯¥measureæ¥å¤„ç†æ•°æ®å¹¶è·å¾—æ‰€éœ€çš„ç»“æœã€‚

![Measures](image/griffin-web-ui-02.png)

* å¦‚æœè¦æµ‹é‡æºå’Œç›®æ ‡ä¹‹é—´çš„åŒ¹é…ç‡ï¼Œè¯·é€‰æ‹©**Accuracy**ã€‚
* å¦‚æœè¦æ£€æŸ¥æ•°æ®çš„ç‰¹å®šå€¼ï¼ˆä¾‹å¦‚ï¼šç©ºåˆ—è®¡æ•°ï¼‰ï¼Œè¯·é€‰æ‹©**Data Profiling**ã€‚

### 5.2.1 Accuracy 
é€šè¿‡ä»·å€¼å¦‚ä½•ä¸ç¡®å®šçš„äº‹å®æ¥æºä¸€è‡´æ¥è¡¡é‡ã€‚

#### 1 Choose source ï¼ˆé€‰æ‹©æ¥æºï¼‰
é€‰æ‹©æˆ‘ä»¬å°†ç”¨äºæ¯”è¾ƒçš„æ•°æ®æºä¸å­—æ®µã€‚é€‰æ‹©`demo-src`

![Choose source](image/griffin-web-ui-03.png)

#### 2 Choose target ï¼ˆé€‰æ‹©ç›®æ ‡ï¼‰
é€‰æ‹©æˆ‘ä»¬å°†ç”¨äºæ¯”è¾ƒçš„æ•°æ®æºä¸å­—æ®µã€‚é€‰æ‹©`demo-tgt`

![Choose target](image/griffin-web-ui-04.png)

#### 3 Mapping source and target ï¼ˆæ˜ å°„sourceå’Œtargetï¼‰
1. "Map To": é€‰æ‹©sourceå’ŒtargetåŒ¹é…çš„è§„åˆ™ã€‚å…±ä»¥ä¸‹6ä¸­é€‰é¡¹:
    * `=` : ä¸¤åˆ—çš„æ•°æ®åº”å®Œå…¨åŒ¹é…ã€‚
    * `!=` : ä¸¤åˆ—çš„æ•°æ®åº”è¯¥ä¸åŒã€‚
    * `> `: ç›®æ ‡åˆ—æ•°æ®åº”å¤§äºæºåˆ—æ•°æ®ã€‚
    * `>=` : ç›®æ ‡åˆ—æ•°æ®åº”å¤§äºæˆ–ç­‰äºæºæ•°æ®ã€‚
    * `< `: ç›®æ ‡åˆ—æ•°æ®åº”å°äºæºåˆ—æ•°æ®ã€‚
    * `<= `: ç›®æ ‡åˆ—æ•°æ®åº”å°äºæˆ–ç­‰äºæºåˆ—æ•°æ®ã€‚

2. "Source fields": é€‰æ‹©è¦ä¸ç›®æ ‡åˆ—è¿›è¡Œæ¯”è¾ƒçš„æºåˆ—ã€‚
![Mapping source and target](image/griffin-web-ui-05.png)

#### 4 Partition Configuration ï¼ˆåˆ†åŒºè®¾ç½®ï¼‰
ä¸ºæºæ•°æ®é›†å’Œç›®æ ‡æ•°æ®é›†è®¾ç½®åˆ†åŒºé…ç½®ã€‚åˆ†åŒºå¤§å°è¡¨ç¤ºhiveæ•°æ®åº“æœ€å°æ•°æ®å•å…ƒï¼Œç”¨äºåˆ†å‰²è¦è®¡ç®—çš„æ•°æ®ã€‚æ¡ä»¶å¡«å†™`dt=#YYYYMMdd# AND hour=#HH#`

`Done file` è¡¨ç¤ºdone fileåˆ†åŒºè·¯å¾„çš„æ ¼å¼ã€‚

![Partition Configuration](image/griffin-web-ui-06.png)

#### 5 Configuration ï¼ˆé…ç½®ï¼‰
è®¾ç½®æ‰€éœ€çš„åº¦é‡ä¿¡æ¯ã€‚organizationä¸ºåº¦é‡çš„ç»„ï¼Œç¨åå¯ä»¥å®‰ç»„æ¥ç®¡ç†åº¦é‡ä»ªè¡¨é¢æ¿ã€‚

![Configuration](image/griffin-web-ui-07.png)


#### 6 Measure information ï¼ˆåº¦é‡ä¿¡æ¯ï¼‰
åˆ›å»ºæ–°çš„ç²¾ç¡®åº¦é‡åï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åˆ—å‡ºçš„åº¦é‡ä¿¡æ¯çš„æ±‡æ€»é¡µé¢ã€‚

![Measure information](image/griffin-web-ui-08.png)

å¯ä»¥çœ‹åˆ°ä¸‹é¢æœ‰ä¸€ä¸ªå‡†ç¡®ç‡çš„è®¡ç®—å…¬å¼ï¼Œå‡å¦‚æºè¡¨Aæœ‰1000æ¡æ•°æ®ï¼Œç›®æ ‡è¡¨Båªæœ‰999æ¡è®°å½•ï¼Œä¸”èƒ½å¤Ÿä¸æ‰€é€‰çš„å­—æ®µä¿¡æ¯åŒ¹é…ï¼Œé‚£ä¹ˆå‡†ç¡®ç‡= 999/1000 * 100ï¼…= 99.9ï¼…ã€‚

## 5.3 åˆ›å»º Job
é€šè¿‡ç‚¹å‡» "Jobs"ï¼Œç„¶åé€‰æ‹© "Create Job"ã€‚æˆ‘ä»¬å¯ä»¥å®šæœŸæäº¤ä½œä¸šä»¥æ‰§è¡Œæµ‹é‡ã€‚

å¡«å…¥å®šæ—¶çš„cron è¡¨è¾¾å¼ã€‚ç°åœ¨ä»…æ”¯æŒç®€å•çš„å®šæœŸè°ƒåº¦å·¥ä½œè¿›è¡Œæµ‹é‡ã€‚
![Create Job](image/griffin-web-ui-09.png)

![Create Job Info](image/griffin-web-ui-10.png)

è¯´æ˜ï¼š
* **Job Name**: è®¾ç½®Jobçš„åå­—
* **Measure Name**: è¦æ‰§è¡Œçš„measureçš„åç§°ï¼Œè¿™ä¸ªæ˜¯ä»å‰é¢åˆ›å»ºçš„Measureçš„åå­—ä¸­é€‰æ‹©ã€‚
* **Cron Expression**: cron è¡¨è¾¾å¼ã€‚ For example: 0 0/4 * * *.
    ```bash
    # For details see man 4 crontabs
    # Example of job definition:
    # .---------------- minute (0 - 59)
    # |  .------------- hour (0 - 23)
    # |  |  .---------- day of month (1 - 31)
    # |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
    # |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
    # |  |  |  |  |
    # *  *  *  *  * user-name  command to be executed
    ```
* **Begin**: æ•°æ®æ®µå¼€å§‹æ—¶é—´ä¸è§¦å‘æ—¶é—´çš„æ¯”è¾ƒ
* **End**: æ•°æ®æ®µç»“æŸæ—¶é—´ä¸è§¦å‘æ—¶é—´æ¯”è¾ƒã€‚

æäº¤ä½œä¸šåï¼ŒApache Griffinå°†åœ¨åå°å®‰æ’ä½œä¸šï¼Œè®¡ç®—å®Œæˆåï¼Œæ‚¨å¯ä»¥ç›‘è§†ä»ªè¡¨æ¿ä»¥åœ¨UIä¸ŠæŸ¥çœ‹ç»“æœã€‚

## 5.4 Metrics ä»ªè¡¨æ¿
* ç‚¹å‡»å¤´éƒ¨çš„`Health`ä¼šæ˜¾ç¤ºæŒ‡æ ‡æ•°æ®çš„çƒ­å›¾ã€‚
* ç‚¹å‡»å³ä¾§çš„`DQ Metrics`å¯ä»¥çœ‹åˆ°æŒ‡æ ‡å›¾æ ‡ã€‚å•å‡»å›¾æ ‡å¯ä»¥æ”¾å¤§ã€‚



<br/><br/>

###### ğŸ‘‰è®¿é—®æˆ‘çš„åšå®¢ [Apache Griffin 5.0 ç¼–è¯‘å®‰è£…å’Œä½¿ç”¨(åŒ…å«ä¾èµ–æ— æ³•ä¸‹è½½çš„é—®é¢˜è§£å†³)](https://blog.csdn.net/github_39577257/article/details/90607081)





